

### ğŸ“„ `README.md` â€” Prompt Health Checker

```markdown
# ğŸ›¡ï¸ Prompt Health Checker

**Prompt Health Checker** is an intelligent LLM safety tool that evaluates user-entered prompts for **privacy**, **bias**, **toxicity**, and **prompt injection** risks. It generates safe alternatives using Cohere and flags risky language using smart rule-based and contextual detection.

> âš¡ Built for AI developers, enterprise compliance teams, researchers, and safety-first LLM startups.

---

## ğŸš€ Features

- ğŸ” **Multi-Risk Detection**  
  Identifies PII exposure, gender bias, prompt injection, and offensive content.

- âœ¨ **Safe Prompt Rewriter**  
  Rewrites unsafe prompts using [Cohere API](https://cohere.ai).

- ğŸ§  **Smart Rule Matching**  
  Context-aware detection (e.g., â€œbrutal attackâ€ vs â€œbrutal workoutâ€).

- ğŸ“Š **Risk Levels**  
  Flags prompts as `Low`, `Medium`, or `High` risk with explanations.

- ğŸ§ª **Developer Mode**  
  Shows matched rules and explanations (toggleable via sidebar).

- ğŸ“ **Batch Analyzer**  
  Upload CSV, PDF, or PNG files and auto-analyze all prompts.

- ğŸ“¥ **Report Export**  
  Download result summaries in CSV format.

- ğŸ–¥ï¸ **Streamlit UI**  
  Clean, interactive UI for tech and non-tech users.

---

## ğŸ§‘â€ğŸ’» Technologies Used

| Stack Layer       | Tools / Libraries                                  |
|-------------------|----------------------------------------------------|
| UI                | [Streamlit](https://streamlit.io)                  |
| NLP & Rewrite     | [Cohere API](https://cohere.ai)                    |
| File Processing   | `pdfplumber`, `pytesseract`, `Pillow`, `pandas`    |
| Detection Engine  | `regex`, contextual keyword rules, rule explanations |
| Deployment Ready  | GitHub, Streamlit Cloud compatible                 |

---

## ğŸ¯ Who Will Benefit?

| User Type               | Benefit                                                                 |
|-------------------------|-------------------------------------------------------------------------|
| ğŸ” LLM Developers        | Test prompts before passing to models like GPT, Claude, Cohere.         |
| ğŸ¢ Enterprise Teams      | Ensure prompts don't leak sensitive or biased data.                     |
| ğŸ§ª Researchers           | Analyze how humans or LLMs phrase potentially unsafe inputs.            |
| ğŸ—‚ï¸ Product Managers      | Deploy pre-validation tools for user-submitted prompts.                 |
| ğŸ§‘â€ğŸ“ Students/Learners    | Learn prompt engineering, AI ethics, and NLP guardrails.                |

---

## ğŸ› ï¸ How to Run Locally

### 1. Clone the repository:

```bash
git clone https://github.com/YOUR_USERNAME/prompt-health-checker.git
cd prompt-health-checker
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Add your Cohere API key

Edit `.streamlit/secrets.toml`:

```toml
COHERE_API_KEY = "your_actual_cohere_key"
```

> ğŸ”‘ Get your API key at https://dashboard.cohere.com

### 4. Run the app

```bash
streamlit run app.py
```



---

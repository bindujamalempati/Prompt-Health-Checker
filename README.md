

# ðŸ›¡ï¸ Prompt Health Checker

**Prompt Health Checker** is a smart LLM safety tool designed to evaluate user-entered prompts for **privacy risks**, **bias**, **toxicity**, and **prompt injection** vulnerabilities. It not only flags risky content but also **suggests safer alternatives** using the Cohere API, making it an essential tool for AI practitioners, enterprises, and researchers focused on safe AI deployment.

> âš¡ Built for AI developers, compliance teams, safety researchers, and LLM-driven startups.

---

## ðŸš€ Features

- ðŸ” **Multi-Risk Detection**  
  Detects personally identifiable information (PII), gender or racial bias, toxic language, and prompt injection attempts.

- âœ¨ **Safe Prompt Rewriter**  
  Automatically rewrites unsafe prompts to safer alternatives using [Cohere's NLP capabilities](https://cohere.ai).

- ðŸ§  **Context-Aware Rule Matching**  
  Understands context to differentiate between benign and harmful uses of language.

- ðŸ“Š **Risk Level Classification**  
  Categorizes each prompt into `Low`, `Medium`, or `High` risk, along with explanations.

- ðŸ§ª **Developer Mode**  
  Optional mode to reveal matched rules, detection reasons, and internal insights.

- ðŸ“ **Batch File Analysis**  
  Upload `.csv`, `.pdf`, or `.png` files to bulk-analyze multiple prompts at once.

- ðŸ“¥ **Export Reports**  
  Download prompt analysis summaries as `.csv` reports.

- ðŸ–¥ï¸ **Interactive Streamlit UI**  
  Modern, user-friendly interface designed for both technical and non-technical users.

---

## ðŸ§‘â€ðŸ’» Technologies Used

| Layer                | Tools / Libraries                                |
|----------------------|--------------------------------------------------|
| Frontend UI          | [Streamlit](https://streamlit.io)                |
| NLP / Rewrite Engine | [Cohere API](https://cohere.ai)                  |
| File Handling        | `pdfplumber`, `pytesseract`, `Pillow`, `pandas`  |
| Risk Detection       | `regex` patterns, keyword rules, context matching |
| Hosting Ready        | GitHub, Streamlit Cloud                         |

---

## ðŸŽ¯ Ideal Users

| Audience                | Purpose                                              |
|--------------------------|------------------------------------------------------|
| ðŸ” LLM Developers         | Pre-scan prompts before model inference.             |
| ðŸ¢ Compliance Teams       | Verify prompt safety and prevent data leaks.         |
| ðŸ§ª AI Ethics Researchers  | Study human and AI-generated unsafe phrasing.        |
| ðŸ—‚ï¸ Product Managers       | Integrate into AI-driven applications' validation steps. |
| ðŸ§‘â€ðŸŽ“ Students / Learners   | Understand prompt safety and AI content moderation. |

---

## ðŸ› ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/prompt-health-checker.git
cd prompt-health-checker
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Set up your Cohere API key

Create a `.streamlit/secrets.toml` file and add:

```toml
COHERE_API_KEY = "your_actual_cohere_api_key"
```

> ðŸ”‘ You can get your Cohere API key by signing up at [Cohere Dashboard](https://dashboard.cohere.com).

### 4. Launch the app

```bash
streamlit run app.py
```

---

## ðŸ“„ Example Usage

- Type or upload prompts into the UI.
- View risk scores (`Low`, `Medium`, `High`).
- Check why a prompt was flagged.
- Let the tool suggest a safer version of your prompt.
- Export the analysis report if needed!

---

## ðŸ“¢ Contributing

I welcome contributions to improve the detection rules, UI/UX, and rewriting engine. Please submit a pull request or open an issue to discuss your ideas.

---



# ðŸ“¬ Contact

For questions, feature requests, or feedback, reach out at:

- ðŸ“§ Email: malempatibinduja54@gmail.com


---

